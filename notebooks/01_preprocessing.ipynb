{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sales Data Preprocessing Notebook\n",
        "\n",
        "This notebook contains comprehensive data preprocessing steps for the sales data dashboard.\n",
        "\n",
        "## Overview\n",
        "- Load and explore sales data\n",
        "- Handle missing values and duplicates\n",
        "- Normalize categories and extract time features\n",
        "- Save cleaned data for dashboard consumption\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the sales data\n",
        "df = pd.read_csv('../data/raw/sales_data.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic data information\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nDuplicate Rows:\")\n",
        "print(f\"Total duplicates: {df.duplicated().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Cleaning and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for cleaning\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Remove duplicates\n",
        "df_clean = df_clean.drop_duplicates()\n",
        "print(f\"After removing duplicates: {df_clean.shape}\")\n",
        "\n",
        "# Handle missing values\n",
        "print(\"\\nMissing values before cleaning:\")\n",
        "print(df_clean.isnull().sum())\n",
        "\n",
        "# Fill missing values\n",
        "df_clean['CUSTOMERNAME'] = df_clean['CUSTOMERNAME'].fillna('Unknown Customer')\n",
        "df_clean['COUNTRY'] = df_clean['COUNTRY'].fillna('Unknown Country')\n",
        "df_clean['PRODUCTLINE'] = df_clean['PRODUCTLINE'].fillna('Unknown Product')\n",
        "df_clean['STATUS'] = df_clean['STATUS'].fillna('Unknown Status')\n",
        "\n",
        "# For numeric columns, fill with median\n",
        "df_clean['SALES'] = df_clean['SALES'].fillna(df_clean['SALES'].median())\n",
        "df_clean['QUANTITYORDERED'] = df_clean['QUANTITYORDERED'].fillna(df_clean['QUANTITYORDERED'].median())\n",
        "\n",
        "print(\"\\nMissing values after cleaning:\")\n",
        "print(df_clean.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert ORDERDATE to datetime\n",
        "df_clean['ORDERDATE'] = pd.to_datetime(df_clean['ORDERDATE'], errors='coerce')\n",
        "\n",
        "# Extract time features\n",
        "df_clean['YEAR'] = df_clean['ORDERDATE'].dt.year\n",
        "df_clean['MONTH'] = df_clean['ORDERDATE'].dt.month\n",
        "df_clean['QUARTER'] = df_clean['ORDERDATE'].dt.quarter\n",
        "df_clean['DAY_OF_WEEK'] = df_clean['ORDERDATE'].dt.day_name()\n",
        "df_clean['MONTH_NAME'] = df_clean['ORDERDATE'].dt.month_name()\n",
        "\n",
        "print(\"Time features extracted successfully!\")\n",
        "print(f\"Date range: {df_clean['ORDERDATE'].min()} to {df_clean['ORDERDATE'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize categorical data\n",
        "df_clean['PRODUCTLINE'] = df_clean['PRODUCTLINE'].str.strip().str.title()\n",
        "df_clean['COUNTRY'] = df_clean['COUNTRY'].str.strip().str.title()\n",
        "df_clean['CUSTOMERNAME'] = df_clean['CUSTOMERNAME'].str.strip().str.title()\n",
        "df_clean['STATUS'] = df_clean['STATUS'].str.strip().str.title()\n",
        "\n",
        "# Ensure numeric columns are properly typed\n",
        "df_clean['SALES'] = pd.to_numeric(df_clean['SALES'], errors='coerce')\n",
        "df_clean['QUANTITYORDERED'] = pd.to_numeric(df_clean['QUANTITYORDERED'], errors='coerce')\n",
        "df_clean['ORDERNUMBER'] = pd.to_numeric(df_clean['ORDERNUMBER'], errors='coerce')\n",
        "\n",
        "print(\"Data normalization completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Analysis and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Sales Data Analysis Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Sales by Product Line\n",
        "product_sales = df_clean.groupby('PRODUCTLINE')['SALES'].sum().sort_values(ascending=False)\n",
        "colors1 = plt.cm.Set3(np.linspace(0, 1, len(product_sales)))\n",
        "bars1 = axes[0,0].bar(product_sales.index, product_sales.values, color=colors1)\n",
        "axes[0,0].set_title('Total Sales by Product Line', fontweight='bold', pad=20)\n",
        "axes[0,0].set_xlabel('Product Line')\n",
        "axes[0,0].set_ylabel('Total Sales ($)')\n",
        "axes[0,0].tick_params(axis='x', rotation=45)\n",
        "# Add value labels on bars\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    axes[0,0].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                   f'${height:,.0f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# 2. Sales by Country (Top 10)\n",
        "country_sales = df_clean.groupby('COUNTRY')['SALES'].sum().sort_values(ascending=False).head(10)\n",
        "colors2 = plt.cm.viridis(np.linspace(0, 1, len(country_sales)))\n",
        "bars2 = axes[0,1].bar(country_sales.index, country_sales.values, color=colors2)\n",
        "axes[0,1].set_title('Top 10 Countries by Sales', fontweight='bold', pad=20)\n",
        "axes[0,1].set_xlabel('Country')\n",
        "axes[0,1].set_ylabel('Total Sales ($)')\n",
        "axes[0,1].tick_params(axis='x', rotation=45)\n",
        "# Add value labels on bars\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    axes[0,1].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "                   f'${height:,.0f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# 3. Sales Trend Over Time\n",
        "monthly_sales = df_clean.groupby(['YEAR', 'MONTH'])['SALES'].sum().reset_index()\n",
        "monthly_sales['DATE'] = pd.to_datetime(monthly_sales[['YEAR', 'MONTH']].assign(DAY=1))\n",
        "axes[1,0].plot(monthly_sales['DATE'], monthly_sales['SALES'], marker='o', linewidth=2, markersize=6, color='#2E86AB')\n",
        "axes[1,0].set_title('Sales Trend Over Time', fontweight='bold', pad=20)\n",
        "axes[1,0].set_xlabel('Date')\n",
        "axes[1,0].set_ylabel('Total Sales ($)')\n",
        "axes[1,0].tick_params(axis='x', rotation=45)\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "# Add trend line\n",
        "z = np.polyfit(range(len(monthly_sales)), monthly_sales['SALES'], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[1,0].plot(monthly_sales['DATE'], p(range(len(monthly_sales))), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "# 4. Order Status Distribution\n",
        "status_counts = df_clean['STATUS'].value_counts()\n",
        "colors4 = plt.cm.Pastel1(np.linspace(0, 1, len(status_counts)))\n",
        "wedges, texts, autotexts = axes[1,1].pie(status_counts.values, labels=status_counts.index, \n",
        "                                        autopct='%1.1f%%', colors=colors4, startangle=90)\n",
        "axes[1,1].set_title('Order Status Distribution', fontweight='bold', pad=20)\n",
        "# Enhance text appearance\n",
        "for autotext in autotexts:\n",
        "    autotext.set_color('white')\n",
        "    autotext.set_fontweight('bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"=\"*60)\n",
        "print(\"VISUALIZATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"ğŸ“Š Total Product Lines: {len(product_sales)}\")\n",
        "print(f\"ğŸŒ Countries Analyzed: {len(country_sales)}\")\n",
        "print(f\"ğŸ“… Time Period: {monthly_sales['DATE'].min().strftime('%B %Y')} to {monthly_sales['DATE'].max().strftime('%B %Y')}\")\n",
        "print(f\"ğŸ“‹ Order Statuses: {len(status_counts)}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced Analytics and Insights\n",
        "print(\"=\"*70)\n",
        "print(\"ADVANCED SALES ANALYTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Top Performing Analysis\n",
        "print(\"\\nğŸ† TOP PERFORMERS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Top Product Line\n",
        "top_product = df_clean.groupby('PRODUCTLINE')['SALES'].sum().idxmax()\n",
        "top_product_sales = df_clean.groupby('PRODUCTLINE')['SALES'].sum().max()\n",
        "print(f\"ğŸ¥‡ Best Product Line: {top_product} (${top_product_sales:,.2f})\")\n",
        "\n",
        "# Top Country\n",
        "top_country = df_clean.groupby('COUNTRY')['SALES'].sum().idxmax()\n",
        "top_country_sales = df_clean.groupby('COUNTRY')['SALES'].sum().max()\n",
        "print(f\"ğŸŒ Top Country: {top_country} (${top_country_sales:,.2f})\")\n",
        "\n",
        "# Top Customer\n",
        "top_customer = df_clean.groupby('CUSTOMERNAME')['SALES'].sum().idxmax()\n",
        "top_customer_sales = df_clean.groupby('CUSTOMERNAME')['SALES'].sum().max()\n",
        "print(f\"ğŸ‘¤ Top Customer: {top_customer} (${top_customer_sales:,.2f})\")\n",
        "\n",
        "# 2. Performance Metrics\n",
        "print(\"\\nğŸ“ˆ PERFORMANCE METRICS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Average Order Value\n",
        "avg_order_value = df_clean['SALES'].mean()\n",
        "print(f\"ğŸ’° Average Order Value: ${avg_order_value:,.2f}\")\n",
        "\n",
        "# Total Revenue\n",
        "total_revenue = df_clean['SALES'].sum()\n",
        "print(f\"ğŸ’µ Total Revenue: ${total_revenue:,.2f}\")\n",
        "\n",
        "# Total Orders\n",
        "total_orders = df_clean['ORDERNUMBER'].nunique()\n",
        "print(f\"ğŸ“¦ Total Orders: {total_orders:,}\")\n",
        "\n",
        "# Total Quantity\n",
        "total_quantity = df_clean['QUANTITYORDERED'].sum()\n",
        "print(f\"ğŸ“Š Total Quantity Sold: {total_quantity:,}\")\n",
        "\n",
        "# 3. Time-based Analysis\n",
        "print(\"\\nâ° TIME-BASED ANALYSIS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Best Month\n",
        "monthly_performance = df_clean.groupby(['YEAR', 'MONTH'])['SALES'].sum()\n",
        "best_month = monthly_performance.idxmax()\n",
        "best_month_sales = monthly_performance.max()\n",
        "print(f\"ğŸ“… Best Month: {best_month[1]}/{best_month[0]} (${best_month_sales:,.2f})\")\n",
        "\n",
        "# Worst Month\n",
        "worst_month = monthly_performance.idxmin()\n",
        "worst_month_sales = monthly_performance.min()\n",
        "print(f\"ğŸ“… Worst Month: {worst_month[1]}/{worst_month[0]} (${worst_month_sales:,.2f})\")\n",
        "\n",
        "# Year-over-Year Growth\n",
        "yearly_sales = df_clean.groupby('YEAR')['SALES'].sum()\n",
        "if len(yearly_sales) > 1:\n",
        "    current_year = yearly_sales.index[-1]\n",
        "    previous_year = yearly_sales.index[-2]\n",
        "    current_sales = yearly_sales[current_year]\n",
        "    previous_sales = yearly_sales[previous_year]\n",
        "    yoy_growth = ((current_sales - previous_sales) / previous_sales) * 100\n",
        "    print(f\"ğŸ“ˆ YoY Growth ({previous_year} to {current_year}): {yoy_growth:+.1f}%\")\n",
        "\n",
        "# 4. Customer Analysis\n",
        "print(\"\\nğŸ‘¥ CUSTOMER ANALYSIS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Customer count\n",
        "unique_customers = df_clean['CUSTOMERNAME'].nunique()\n",
        "print(f\"ğŸ‘¤ Unique Customers: {unique_customers:,}\")\n",
        "\n",
        "# Average orders per customer\n",
        "avg_orders_per_customer = total_orders / unique_customers\n",
        "print(f\"ğŸ“¦ Average Orders per Customer: {avg_orders_per_customer:.1f}\")\n",
        "\n",
        "# Customer concentration (top 10 customers)\n",
        "top_10_customers = df_clean.groupby('CUSTOMERNAME')['SALES'].sum().nlargest(10)\n",
        "top_10_percentage = (top_10_customers.sum() / total_revenue) * 100\n",
        "print(f\"ğŸ¯ Top 10 Customers Revenue Share: {top_10_percentage:.1f}%\")\n",
        "\n",
        "# 5. Product Analysis\n",
        "print(\"\\nğŸ·ï¸ PRODUCT ANALYSIS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Product diversity\n",
        "unique_products = df_clean['PRODUCTLINE'].nunique()\n",
        "print(f\"ğŸ·ï¸ Product Lines: {unique_products}\")\n",
        "\n",
        "# Product concentration\n",
        "top_product_share = (top_product_sales / total_revenue) * 100\n",
        "print(f\"ğŸ¥‡ Top Product Share: {top_product_share:.1f}%\")\n",
        "\n",
        "# Average sales per product\n",
        "avg_sales_per_product = total_revenue / unique_products\n",
        "print(f\"ğŸ“Š Average Sales per Product Line: ${avg_sales_per_product:,.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Quality Assessment and Validation\n",
        "print(\"=\"*70)\n",
        "print(\"DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Data Completeness Check\n",
        "print(\"\\nâœ… DATA COMPLETENESS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "total_records = len(df_clean)\n",
        "print(f\"ğŸ“Š Total Records: {total_records:,}\")\n",
        "\n",
        "# Check for missing values after cleaning\n",
        "missing_values = df_clean.isnull().sum()\n",
        "missing_percentage = (missing_values / total_records) * 100\n",
        "\n",
        "print(\"\\nMissing Values Analysis:\")\n",
        "for column, missing_count in missing_values.items():\n",
        "    if missing_count > 0:\n",
        "        print(f\"âš ï¸  {column}: {missing_count} missing ({missing_percentage[column]:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"âœ… {column}: No missing values\")\n",
        "\n",
        "# 2. Data Consistency Check\n",
        "print(\"\\nğŸ” DATA CONSISTENCY:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Check for negative sales\n",
        "negative_sales = (df_clean['SALES'] < 0).sum()\n",
        "print(f\"ğŸ’° Negative Sales: {negative_sales} records\")\n",
        "\n",
        "# Check for zero sales\n",
        "zero_sales = (df_clean['SALES'] == 0).sum()\n",
        "print(f\"ğŸ’° Zero Sales: {zero_sales} records\")\n",
        "\n",
        "# Check for negative quantities\n",
        "negative_quantities = (df_clean['QUANTITYORDERED'] < 0).sum()\n",
        "print(f\"ğŸ“¦ Negative Quantities: {negative_quantities} records\")\n",
        "\n",
        "# Check for zero quantities\n",
        "zero_quantities = (df_clean['QUANTITYORDERED'] == 0).sum()\n",
        "print(f\"ğŸ“¦ Zero Quantities: {zero_quantities} records\")\n",
        "\n",
        "# 3. Data Range Analysis\n",
        "print(\"\\nğŸ“ˆ DATA RANGE ANALYSIS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(f\"ğŸ’° Sales Range: ${df_clean['SALES'].min():,.2f} - ${df_clean['SALES'].max():,.2f}\")\n",
        "print(f\"ğŸ“¦ Quantity Range: {df_clean['QUANTITYORDERED'].min():,} - {df_clean['QUANTITYORDERED'].max():,}\")\n",
        "print(f\"ğŸ“… Date Range: {df_clean['ORDERDATE'].min().strftime('%Y-%m-%d')} to {df_clean['ORDERDATE'].max().strftime('%Y-%m-%d')}\")\n",
        "\n",
        "# 4. Outlier Detection\n",
        "print(\"\\nğŸ¯ OUTLIER DETECTION:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Sales outliers using IQR method\n",
        "Q1_sales = df_clean['SALES'].quantile(0.25)\n",
        "Q3_sales = df_clean['SALES'].quantile(0.75)\n",
        "IQR_sales = Q3_sales - Q1_sales\n",
        "lower_bound_sales = Q1_sales - 1.5 * IQR_sales\n",
        "upper_bound_sales = Q3_sales + 1.5 * IQR_sales\n",
        "\n",
        "sales_outliers = df_clean[(df_clean['SALES'] < lower_bound_sales) | (df_clean['SALES'] > upper_bound_sales)]\n",
        "print(f\"ğŸ’° Sales Outliers: {len(sales_outliers)} records ({len(sales_outliers)/total_records*100:.1f}%)\")\n",
        "\n",
        "# Quantity outliers\n",
        "Q1_qty = df_clean['QUANTITYORDERED'].quantile(0.25)\n",
        "Q3_qty = df_clean['QUANTITYORDERED'].quantile(0.75)\n",
        "IQR_qty = Q3_qty - Q1_qty\n",
        "lower_bound_qty = Q1_qty - 1.5 * IQR_qty\n",
        "upper_bound_qty = Q3_qty + 1.5 * IQR_qty\n",
        "\n",
        "qty_outliers = df_clean[(df_clean['QUANTITYORDERED'] < lower_bound_qty) | (df_clean['QUANTITYORDERED'] > upper_bound_qty)]\n",
        "print(f\"ğŸ“¦ Quantity Outliers: {len(qty_outliers)} records ({len(qty_outliers)/total_records*100:.1f}%)\")\n",
        "\n",
        "# 5. Data Distribution Summary\n",
        "print(\"\\nğŸ“Š DATA DISTRIBUTION SUMMARY:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(\"Sales Distribution:\")\n",
        "print(f\"  Mean: ${df_clean['SALES'].mean():,.2f}\")\n",
        "print(f\"  Median: ${df_clean['SALES'].median():,.2f}\")\n",
        "print(f\"  Std Dev: ${df_clean['SALES'].std():,.2f}\")\n",
        "\n",
        "print(\"\\nQuantity Distribution:\")\n",
        "print(f\"  Mean: {df_clean['QUANTITYORDERED'].mean():.1f}\")\n",
        "print(f\"  Median: {df_clean['QUANTITYORDERED'].median():.1f}\")\n",
        "print(f\"  Std Dev: {df_clean['QUANTITYORDERED'].std():.1f}\")\n",
        "\n",
        "# 6. Final Data Quality Score\n",
        "print(\"\\nğŸ† DATA QUALITY SCORE:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "quality_score = 100\n",
        "if missing_values.sum() > 0:\n",
        "    quality_score -= (missing_values.sum() / (total_records * len(df_clean.columns))) * 50\n",
        "if negative_sales > 0 or negative_quantities > 0:\n",
        "    quality_score -= 10\n",
        "if len(sales_outliers) > total_records * 0.05:  # More than 5% outliers\n",
        "    quality_score -= 5\n",
        "\n",
        "print(f\"ğŸ“Š Overall Data Quality Score: {quality_score:.1f}/100\")\n",
        "if quality_score >= 90:\n",
        "    print(\"âœ… Excellent data quality!\")\n",
        "elif quality_score >= 80:\n",
        "    print(\"âœ… Good data quality!\")\n",
        "elif quality_score >= 70:\n",
        "    print(\"âš ï¸  Fair data quality - some issues detected\")\n",
        "else:\n",
        "    print(\"âŒ Poor data quality - significant issues detected\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save cleaned data and generate final summary\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL DATA EXPORT AND SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save the cleaned data\n",
        "output_path = '../data/processed/sales_cleaned.csv'\n",
        "df_clean.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\nğŸ’¾ CLEANED DATA SAVED:\")\n",
        "print(f\"ğŸ“ Location: {output_path}\")\n",
        "print(f\"ğŸ“Š Records: {len(df_clean):,}\")\n",
        "print(f\"ğŸ“‹ Columns: {len(df_clean.columns)}\")\n",
        "\n",
        "# Display final data sample\n",
        "print(f\"\\nğŸ“‹ FINAL DATA SAMPLE:\")\n",
        "print(\"-\" * 40)\n",
        "print(df_clean.head())\n",
        "\n",
        "# Final summary statistics\n",
        "print(f\"\\nğŸ“ˆ FINAL SUMMARY STATISTICS:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"ğŸ“Š Dataset Shape: {df_clean.shape}\")\n",
        "print(f\"ğŸ’° Total Sales: ${df_clean['SALES'].sum():,.2f}\")\n",
        "print(f\"ğŸ“¦ Total Orders: {df_clean['ORDERNUMBER'].nunique():,}\")\n",
        "print(f\"ğŸ‘¤ Unique Customers: {df_clean['CUSTOMERNAME'].nunique():,}\")\n",
        "print(f\"ğŸŒ Countries: {df_clean['COUNTRY'].nunique()}\")\n",
        "print(f\"ğŸ·ï¸ Product Lines: {df_clean['PRODUCTLINE'].nunique()}\")\n",
        "print(f\"ğŸ“… Date Range: {df_clean['ORDERDATE'].min().strftime('%Y-%m-%d')} to {df_clean['ORDERDATE'].max().strftime('%Y-%m-%d')}\")\n",
        "\n",
        "# Column information\n",
        "print(f\"\\nğŸ“‹ FINAL COLUMN INFORMATION:\")\n",
        "print(\"-\" * 40)\n",
        "for i, col in enumerate(df_clean.columns, 1):\n",
        "    dtype = df_clean[col].dtype\n",
        "    non_null = df_clean[col].count()\n",
        "    print(f\"{i:2d}. {col:<20} | Type: {str(dtype):<12} | Non-null: {non_null:,}\")\n",
        "\n",
        "print(f\"\\nâœ… DATA PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ¯ The cleaned data is now ready for:\")\n",
        "print(\"   â€¢ Backend API consumption\")\n",
        "print(\"   â€¢ Frontend dashboard visualization\")\n",
        "print(\"   â€¢ AI/ML model training\")\n",
        "print(\"   â€¢ Business intelligence analysis\")\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
